
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://rickyding1997.github.io/Study-Notes-2025/NeuroAI/2017_NeuroAI_2.html">
      
      
        <link rel="prev" href="2017_NeuroAI_1.html">
      
      
        <link rel="next" href="Neuromatch_course.html">
      
      
      <link rel="icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.15">
    
    
      
        <title>2017 NeuroAI 2 - Ricky's Study Notes</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.342714a4.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../css/main.css">
    
      <link rel="stylesheet" href="https://unpkg.com/katex@0/dist/katex.min.css">
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    <body dir="ltr">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#deep-learning" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../index.html" title="Ricky&#39;s Study Notes" class="md-header__button md-logo" aria-label="Ricky's Study Notes" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Ricky's Study Notes
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              2017 NeuroAI 2
            
          </span>
        </div>
      </div>
    </div>
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../index.html" title="Ricky&#39;s Study Notes" class="md-nav__button md-logo" aria-label="Ricky's Study Notes" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    Ricky's Study Notes
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../index.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../DeepSeek.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    DeepSeek
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../RL.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    RL
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" checked>
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    NeuroAI
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            NeuroAI
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="2017_NeuroAI_1.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    2017 NeuroAI 1
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    2017 NeuroAI 2
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="2017_NeuroAI_2.html" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    2017 NeuroAI 2
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#deep-learning" class="md-nav__link">
    <span class="md-ellipsis">
      Deep Learning
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Deep Learning">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#sota-2025" class="md-nav__link">
    <span class="md-ellipsis">
      SOTA 2025
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#reinforcement-learning" class="md-nav__link">
    <span class="md-ellipsis">
      Reinforcement Learning
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Reinforcement Learning">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#sota-2025_1" class="md-nav__link">
    <span class="md-ellipsis">
      SOTA 2025
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#attention" class="md-nav__link">
    <span class="md-ellipsis">
      Attention
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Attention">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#sota-2025_2" class="md-nav__link">
    <span class="md-ellipsis">
      SOTA 2025
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#episodic-memory" class="md-nav__link">
    <span class="md-ellipsis">
      Episodic Memory
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Episodic Memory">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#sota-2025_3" class="md-nav__link">
    <span class="md-ellipsis">
      SOTA 2025
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#working-memory" class="md-nav__link">
    <span class="md-ellipsis">
      Working Memory
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Working Memory">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#sota-2025_4" class="md-nav__link">
    <span class="md-ellipsis">
      SOTA 2025
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#continual-learning" class="md-nav__link">
    <span class="md-ellipsis">
      Continual Learning
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#intuitive-understanding-of-the-physical-world" class="md-nav__link">
    <span class="md-ellipsis">
      Intuitive Understanding of the Physical World
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Intuitive Understanding of the Physical World">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#sota-2025_5" class="md-nav__link">
    <span class="md-ellipsis">
      SOTA 2025
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#efficient-learning" class="md-nav__link">
    <span class="md-ellipsis">
      Efficient Learning
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#transfer-learning" class="md-nav__link">
    <span class="md-ellipsis">
      Transfer Learning
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Transfer Learning">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#sota-2025_6" class="md-nav__link">
    <span class="md-ellipsis">
      SOTA 2025
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#imagination-and-planning" class="md-nav__link">
    <span class="md-ellipsis">
      Imagination and Planning
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Imagination and Planning">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#sota-2025_7" class="md-nav__link">
    <span class="md-ellipsis">
      SOTA 2025
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#virtual-brain-analytics" class="md-nav__link">
    <span class="md-ellipsis">
      Virtual Brain Analytics
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Virtual Brain Analytics">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#sota-2025_8" class="md-nav__link">
    <span class="md-ellipsis">
      SOTA 2025
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#extra" class="md-nav__link">
    <span class="md-ellipsis">
      Extra
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="Neuromatch_course.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Neuromatch course
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" >
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Trading
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            Trading
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../trading/options.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Options
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#deep-learning" class="md-nav__link">
    <span class="md-ellipsis">
      Deep Learning
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Deep Learning">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#sota-2025" class="md-nav__link">
    <span class="md-ellipsis">
      SOTA 2025
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#reinforcement-learning" class="md-nav__link">
    <span class="md-ellipsis">
      Reinforcement Learning
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Reinforcement Learning">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#sota-2025_1" class="md-nav__link">
    <span class="md-ellipsis">
      SOTA 2025
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#attention" class="md-nav__link">
    <span class="md-ellipsis">
      Attention
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Attention">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#sota-2025_2" class="md-nav__link">
    <span class="md-ellipsis">
      SOTA 2025
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#episodic-memory" class="md-nav__link">
    <span class="md-ellipsis">
      Episodic Memory
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Episodic Memory">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#sota-2025_3" class="md-nav__link">
    <span class="md-ellipsis">
      SOTA 2025
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#working-memory" class="md-nav__link">
    <span class="md-ellipsis">
      Working Memory
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Working Memory">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#sota-2025_4" class="md-nav__link">
    <span class="md-ellipsis">
      SOTA 2025
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#continual-learning" class="md-nav__link">
    <span class="md-ellipsis">
      Continual Learning
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#intuitive-understanding-of-the-physical-world" class="md-nav__link">
    <span class="md-ellipsis">
      Intuitive Understanding of the Physical World
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Intuitive Understanding of the Physical World">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#sota-2025_5" class="md-nav__link">
    <span class="md-ellipsis">
      SOTA 2025
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#efficient-learning" class="md-nav__link">
    <span class="md-ellipsis">
      Efficient Learning
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#transfer-learning" class="md-nav__link">
    <span class="md-ellipsis">
      Transfer Learning
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Transfer Learning">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#sota-2025_6" class="md-nav__link">
    <span class="md-ellipsis">
      SOTA 2025
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#imagination-and-planning" class="md-nav__link">
    <span class="md-ellipsis">
      Imagination and Planning
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Imagination and Planning">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#sota-2025_7" class="md-nav__link">
    <span class="md-ellipsis">
      SOTA 2025
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#virtual-brain-analytics" class="md-nav__link">
    <span class="md-ellipsis">
      Virtual Brain Analytics
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Virtual Brain Analytics">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#sota-2025_8" class="md-nav__link">
    <span class="md-ellipsis">
      SOTA 2025
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#extra" class="md-nav__link">
    <span class="md-ellipsis">
      Extra
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  



  <h1>2017 NeuroAI 2</h1>

<h2 id="deep-learning">Deep Learning</h2>
<ul>
<li>1943, McCulloch and Pitts: NN that could compute logical functions</li>
<li>1949, Hebb: efficiently encode environmental statistics in an unsupervised fashion</li>
<li>1958, Rosenblatt: NN learn incrementally via supervisory feedback</li>
<li>1980, Fukushima: early NN models of visual processing</li>
<li>1985, Rumelhart: backprop</li>
<li>2006, Hinton: deep belief networks</li>
<li>2009, Deng: introduction of large datasets inspired by research on human language</li>
<li>2012, Hinton: Dropout regularization, motivated by the stochasticity that is inherent in neurons that fire with Poisson-like statistics</li>
<li>2015, LeCun: sentences can be represented as vectors</li>
<li>2016, Yamins and DiCarlo: CNNs incorporate nonlinear transduction, divisive normalization, and maximum based pooling of inputs<ul>
<li>1959, Hubel and Wiesel: single-cell recordings from the mammalian visual cortex revealed how visual input is filtered and pooled in simple and complex cells in area V1</li>
<li>Replicates the hierarchical organization of mammalian cortical systems, with both convergent and divergent information flow in successive, nested processing layers </li>
</ul>
</li>
</ul>
<h3 id="sota-2025">SOTA 2025</h3>
<ul>
<li>LLMs</li>
</ul>
<h2 id="reinforcement-learning">Reinforcement Learning</h2>
<ul>
<li>
<p>TD methods </p>
<ul>
<li>Real-time models that learn from differences between temporally successive <strong>predictions</strong>, rather than having to wait until the actual reward is delivered. </li>
<li>Of particular relevance was an effect called second-order conditioning, where affective significance is conferred on a conditioned stimulus (CS) through association with another CS rather than directly via association with the unconditioned stimulus. </li>
<li>TD learning provides a natural explanation for second-order conditioning and indeed has gone on to explain a much wider range of findings from neuroscience.</li>
</ul>
</li>
<li>
<p>TD based RL: DQNs, A3C, PPO (TD for value estimation), SAC (TD for Q-function updates)  </p>
<ul>
<li>DQN uses TD learning by bootstrapping from its own predictions <span class="arithmatex">\(Q_{\text{target}}\)</span> to update Q-values in real time.</li>
<li>Unlike Monte Carlo, it doesn’t need to wait for final outcomes — it learns from temporal differences between successive predictions.</li>
<li>The "real-time" aspect comes from the fact that every step generates a TD error, which is used to improve the policy immediately.</li>
</ul>
</li>
</ul>
<h3 id="sota-2025_1">SOTA 2025</h3>
<ul>
<li>DreamerV3: Best for model-based RL from pixels</li>
<li>MuZero: Combines planning + learning without knowing environment rules</li>
<li>SAC: SOTA for continuous control</li>
<li>PPO: Widely used, stable, scalable</li>
</ul>
<hr />
<h2 id="attention">Attention</h2>
<ul>
<li>Traditionally, CNN models worked directly on entire images, with equal priority given to all pixels at the earliest stage of processing</li>
<li>The primate visual system works differently.  Visual attention shifts strategically among locations and objects, centering processing resources and representational coordinates on a series of regions in turn</li>
<li>
<p>Attentional mechanisms have been a source of inspiration for AI architectures that take "glimpses" of the input image at each step, update internal state representations, and then select the next location to sample </p>
<ul>
<li>One such network was able to use this selective attentional mechanism to ignore irrelevant objects in a scene, allowing it to perform well in challenging object classification tasks in the presence of clutter </li>
<li><a href="https://arxiv.org/pdf/1406.6247">2014. DeepMind. Recurrent Models of Visual Attention</a></li>
</ul>
</li>
<li>
<p>While attention is typically thought of as an orienting mechanism for perception, it can also be focused toward the contents of internal memory, this has helped provide recent successes in machine translation and memory + reasoning tasks</p>
</li>
<li>
<p>One further area of AI where attention mechanisms have recently proven useful focuses on generative models that mimic the structure of examples presented during training</p>
<ul>
<li>For example, in one SOTA generative model known as DRAW, attention allows the system to build up an image incrementally, attending to one portion of a "mental canvas" at a time</li>
</ul>
</li>
</ul>
<h3 id="sota-2025_2">SOTA 2025</h3>
<ul>
<li>LLMs</li>
</ul>
<h2 id="episodic-memory">Episodic Memory</h2>
<ul>
<li>
<p>Allow experiences to be encoded rapidly in a content-addressable store </p>
<ul>
<li>Associated with medial temporal lobe, (including hippocampus)</li>
</ul>
</li>
<li>
<p>Animal learning is supported by complementary learning systems in the hippocampus and neocortex</p>
<ul>
<li>The hippocampus acts to encode novel information after a single exposure (one-shot learning), but this information is gradually consolidated to the neocortex in sleep or resting periods that are interleaved with periods of activity. This consolidation is accompanied by replay in the hippocampus and neocortex, which is observed as a reinstatement of the structured patterns of neural activity that accompanied the learning event </li>
<li>This theory was originally proposed as a solution to the well-known problem that in conventional neural networks, correlated exposure to sequential task settings leads to interference (catastrophic forgetting)</li>
<li>The replay buffer in DQN is like a primitive hippocampus, permitting complementary learning in silico</li>
<li>Enhanced when replay of highly rewarding events is prioritized (hippocampal replay seems to favor events that lead to high levels of reinforcement)<ul>
<li><a href="https://arxiv.org/abs/1511.05952">2015. DeepMind. Prioritized Experience Replay</a></li>
</ul>
</li>
</ul>
</li>
<li>
<p>DQN exhibits expert play on Atari video games by learning to transform image pixels to a policy</p>
<ul>
<li>Experience replay is critical to maximizing data efficiency, avoids the destabilizing effects of learning from consecutive correlated experiences, and allows the network to learn a viable value function even in complex sequential environments (video games)</li>
</ul>
</li>
<li>
<p>Episodic Control</p>
<ul>
<li>Experiences stored in a memory buffer can not only be used to gradually adjust the parameters of a deep network toward an optimal policy, as in DQN</li>
<li>Can also support rapid behavioral change based on an individual experience. Neuroscience has argued for the potential benefits of episodic control, whereby rewarded action sequences can be internally re-enacted from a rapidly updatable memory store (hippocampus). Advantageous when limited experience has been obtained</li>
<li>Recent AI research has drawn on these ideas to overcome the slow learning in deep RL<ul>
<li><a href="https://arxiv.org/abs/1606.04460">2016. DeepMind. Model-Free Episodic Control</a></li>
</ul>
</li>
<li>These networks store experiences (e.g., actions and reward outcomes associated with particular game screens) and select new actions based on the similarity between the current input and memories, taking the reward associated with previous events into account</li>
<li>Striking gains in performance over deep RL. Further, they are able to achieve success on tasks that depend heavily on one-shot learning, where typical deep RL architectures fail</li>
<li>In the future, it will be interesting to harness the benefits of rapid episodic-like memory and more traditional incremental learning (Imagination and planning)</li>
</ul>
</li>
</ul>
<h3 id="sota-2025_3">SOTA 2025</h3>
<ul>
<li>
<p>Problems with Episodic Control</p>
<ul>
<li>You can't store all the experience.</li>
<li>Similar inputs don’t always lead to similar outcomes.</li>
</ul>
</li>
<li>
<p>How World Models solves them</p>
<ul>
<li>Compression &amp; Generalization: World models summarize and compress many experiences into learned patterns</li>
<li>Variance Reduction: world models learn structure and smooth out noise in the data</li>
<li>Predictive Imagination: World models allow simulation of counterfactuals: What if I try a different action in this situation?</li>
</ul>
</li>
</ul>
<h2 id="working-memory">Working Memory</h2>
<ul>
<li>
<p>Human working memory</p>
<ul>
<li>Thought to be instantiated within the prefrontal cortex and interconnected areas. </li>
<li>Classic cognitive theories: depends on interactions between a central controller and separate, domain-specific memory buffers</li>
</ul>
</li>
<li>
<p>Began with RNN displaying attractor dynamics and rich sequential behavior, directly inspired by neuroscience</p>
</li>
<li>
<p>One can see close parallels between the learning dynamics in these early, neuroscience-inspired networks and those in LSTM networks. LTSMs allow information to be gated into a fixed activity state and maintained until an appropriate output is required. The functions of sequence control and memory storage are closely intertwined instead of separate</p>
</li>
<li>
<p>Differential neural computer (DNC) involves a neural network controller that attends to and reads/writes from an external memory matrix. </p>
<ul>
<li>This externalization allows the network controller to learn from scratch (i.e., via end-to-end optimization) to perform a wide range of complex memory and reasoning tasks that currently elude LSTMs, such as finding the shortest path through a graph-like structure</li>
<li>These types of problems were previously argued to depend exclusively on symbol processing and variable binding and therefore beyond the purview of neural networks</li>
</ul>
</li>
<li>
<p>Although both LSTMs and the DNC are described here in the context of working memory, they have the potential to maintain information over many thousands of training cycles and so may thus be suited to longer-term forms of memory, such as retaining and understanding the contents of a book.</p>
</li>
</ul>
<h3 id="sota-2025_4">SOTA 2025</h3>
<ul>
<li>Transformers (implicit memory)</li>
</ul>
<h2 id="continual-learning">Continual Learning</h2>
<ul>
<li>
<p>Neuroscience</p>
<ul>
<li>Decreased synaptic lability (lower rates of plasticity) in a proportion of strengthened synapses, mediated by enlargements to dendritic spines that persist despite learning of other tasks. </li>
<li>Theoretical models: memories can be protected from interference through synapses that transition between a cascade of states with different levels of plasticity.</li>
</ul>
</li>
<li>
<p>Elastic Weight Consolidation (EWC)</p>
<ul>
<li><a href="https://arxiv.org/abs/1612.00796">2016. DeepMind. Overcoming catastrophic forgetting in neural networks</a></li>
<li>Acts by slowing down learning in a subset of network weights identified as important to previous tasks. Allows deep RL networks to support continual learning at large scale.</li>
</ul>
</li>
</ul>
<hr />
<h2 id="intuitive-understanding-of-the-physical-world">Intuitive Understanding of the Physical World</h2>
<ul>
<li>
<p>Novel neural network architectures </p>
<ul>
<li>Interpret and reason about scenes in a human-like way, by decomposing them into individual objects and their relations</li>
<li><a href="https://arxiv.org/abs/1612.00222">2016. DeepMind. Interaction Networks for Learning about Objects, Relations and Physics</a></li>
<li><a href="https://arxiv.org/abs/1603.08575">2016. DeepMind. Attend, Infer, Repeat: Fast Scene Understanding with Generative Models</a></li>
<li><a href="https://arxiv.org/pdf/1706.01427">2017. DeepMind. A simple neural network module for relational reasoning</a><ul>
<li>Human-level performance on challenging reasoning tasks </li>
</ul>
</li>
</ul>
</li>
<li>
<p>Deep RL</p>
<ul>
<li>Capture the processes by which children gain commonsense understanding of the world through interactive experiments.</li>
<li><a href="https://arxiv.org/abs/1611.01843">2016. DeepMind. Learning to Perform Physics Experiments via Deep Reinforcement Learning</a> </li>
</ul>
</li>
<li>
<p>Deep generative models </p>
<ul>
<li>Construct rich object models from raw sensory inputs </li>
<li><a href="https://arxiv.org/abs/1606.05579">2016. DeepMind. Early Visual Concept Learning with Unsupervised Deep Learning</a></li>
<li>Leverage constraints first identified in neuroscience, such as redundancy reduction, which encourage the emergence of disentangled representations of independent factors such as shape and position.</li>
</ul>
</li>
</ul>
<h3 id="sota-2025_5">SOTA 2025</h3>
<ul>
<li>
<p><a href="https://arxiv.org/abs/2106.01345">2021. UC Berkeley. Decision Transformer: Reinforcement Learning via Sequence Modeling</a></p>
<ul>
<li>An architecture that casts the problem of RL as conditional sequence modeling. Unlike prior approaches to RL that fit value functions or compute policy gradients, Decision Transformer simply outputs the optimal actions by leveraging a causally masked Transformer</li>
<li>Matches or exceeds the performance of state-of-the-art model-free offline RL baselines on Atari, OpenAI Gym, and Key-to-Door tasks</li>
</ul>
</li>
<li>
<p><a href="https://arxiv.org/abs/2301.08243">2023. Meta. Self-Supervised Learning from Images with a Joint-Embedding Predictive Architecture</a></p>
<ul>
<li>Grounded in the fact that humans learn an enormous amount of background knowledge about the world just by passively observing it.</li>
<li>At a high level, the JEPA aims to predict the representation of part of an input (such as an image or piece of text) from the representation of other parts of the same input. </li>
<li>Because it does not involve collapsing representations from multiple views/augmentations of an image to a single point, the hope is for the JEPA to avoid the biases and issues associated with another widely used method called invariance-based pretraining.</li>
</ul>
</li>
</ul>
<h2 id="efficient-learning">Efficient Learning</h2>
<ul>
<li>Learn to learn <ul>
<li>Acquiring knowledge on new tasks by leveraging prior experience with related problems, to support one-shot concept learning and accelerating learning in RL tasks</li>
<li><a href="https://arxiv.org/abs/1605.06065">2016. DeepMind. One-shot Learning with Memory-Augmented Neural Networks (MANN)</a><ul>
<li>The <strong>Neural Turing Machine (NTM)</strong> is a fully differentiable implementation of a MANN</li>
</ul>
</li>
<li><a href="https://arxiv.org/abs/1606.04080">2016. DeepMind. <strong>Matching Networks</strong> for One Shot Learning</a><ul>
<li>A new neural architecture that, by way of its corresponding training regime, is capable of state-of-the-art performance on a variety of one-shot classification tasks.</li>
</ul>
</li>
<li><a href="https://arxiv.org/abs/1611.05763">2016. DeepMind. Learning to reinforcement learn</a></li>
<li><a href="https://arxiv.org/abs/1703.03400">2017. Finn. Model-Agnostic Meta-Learning (MAML) for Fast Adaptation of Deep Networks</a></li>
</ul>
</li>
</ul>
<h2 id="transfer-learning">Transfer Learning</h2>
<ul>
<li>
<p>Progressive Neural Networks: a new class of architecture</p>
<ul>
<li><a href="https://arxiv.org/abs/1606.04671">2016. DeepMind. Progressive Neural Networks</a></li>
<li><a href="https://arxiv.org/abs/1610.04286">2016. DeepMind. Sim-to-Real Robot Learning from Pixels with Progressive Nets</a></li>
<li>Leverage knowledge gained in one video game to learn rapidly in another</li>
<li>The proposed architecture bears some resemblance to a successful computational model of sequential task learning in humans.</li>
</ul>
</li>
<li>
<p>Neuroscience</p>
<ul>
<li>How humans or other animals achieve this sort of high-level transfer learning is unknown, and remains a relatively unexplored topic in neuroscience</li>
<li>At the level of neural coding, this kind of transfer of abstract structured knowledge may rely on the formation of conceptual representations that are invariant to the objects, individuals, or scene elements that populate a sensory domain but code instead for abstract, relational information among patterns of inputs (lack direct evidence)</li>
<li>One recent report: neural codes thought to be important in the representation of allocentric (map-like) spaces might be critical for abstract reasoning in more general domains</li>
<li>In the mammalian entorhinal cortex, cells encode the geometry of allocentric space with a periodic <strong>"grid" code</strong>, with receptive fields that tile the local space in a hexagonal pattern (Rowland et al., 2016)</li>
</ul>
</li>
</ul>
<h3 id="sota-2025_6">SOTA 2025</h3>
<ul>
<li>
<p>LLMs!</p>
</li>
<li>
<p>World Models</p>
<ul>
<li><a href="https://ai.meta.com/blog/yann-lecun-ai-model-i-jepa">I-JEPA: The first AI model based on Yann LeCun's vision for more human-like AI</a></li>
</ul>
</li>
</ul>
<h2 id="imagination-and-planning">Imagination and Planning</h2>
<ul>
<li>
<p>Model-free RL</p>
<ul>
<li>Computationally inexpensive</li>
<li>Data inefficient</li>
<li>Inflexible (insensitive to changes in the value of outcomes)</li>
<li><a href="https://www.nature.com/articles/nn1560">2005. Daw. Uncertainty-based competition between prefrontal and dorsolateral striatal systems for behavioral control</a></li>
<li><a href="https://www.sciencedirect.com/science/article/pii/S0896627313008052">2013. Dolan and Dayan. Goals and Habits in the Brain</a></li>
<li><a href="https://psycnet.apa.org/doiLanding?doi=10.1037%2Fh0061626">1948. Tolman. Cognitive maps in rats and men</a></li>
</ul>
</li>
<li>
<p>Monte Carlo tree search (MCTS): use forward search to update a value function and/or policy</p>
<ul>
<li><a href="https://www.scopus.com/pages/publications/84858960516">2012. Browne. A survey of Monte Carlo tree search methods</a></li>
<li><a href="https://www.nature.com/articles/nature16961">2016. Silver. Mastering the game of Go with deep neural networks and tree search</a></li>
</ul>
</li>
<li>
<p>Limitations</p>
<ul>
<li>How rich internal models can be learned through experience without strong priors being handcrafted into the network by the experimenter?</li>
</ul>
</li>
<li>
<p>Hippocampus: imagine possible scenarios &amp; simulation based planning</p>
<ul>
<li>Example: when paused at a choice point, ripples of neural activity in the rat hippocampus resemble those observed during subsequent navigation of the available trajectories ("preplay"), as if the animal were "imagining" each possible alternative</li>
<li>Supports planning by instantiating an internal model of the environment, with goal-contingent valuation of simulated outcomes occurring in areas downstream of the hippocampus such the orbitofrontal cortex or striatum</li>
<li>Mechanisms that guide the rolling forward of an internal model of the environment in the hippocampus remain uncertain and merit future scrutiny (One possibility is that this process is initiated by the prefrontal cortex through interactions with the hippocampus)</li>
<li><a href="https://arxiv.org/abs/1705.02670">2017. Hamrick. Metacontrol for Adaptive Imagination-Based Optimization</a></li>
</ul>
</li>
<li>
<p>Deep generative models for simulation-based
planning</p>
<ul>
<li><a href="https://arxiv.org/abs/1603.08575">2016. Eslami. Attend, Infer, Repeat: Fast Scene Understanding with Generative Models</a></li>
<li><a href="https://arxiv.org/abs/1607.00662">2016. Rezende. Unsupervised Learning of 3D Structure from Images</a></li>
<li><a href="https://arxiv.org/abs/1603.05106">2016. Rezende. One-Shot Generalization in Deep Generative Models</a></li>
<li>Generate temporally consistent sequences of generated samples that reflect the geometric layout of newly experienced realistic environments<ul>
<li><a href="https://arxiv.org/abs/1702.04649">2017. Gemici. Generative Temporal Models with Memory</a></li>
<li><a href="https://arxiv.org/abs/1507.08750">2015. Oh. Action-Conditional Video Prediction using Deep Networks in Atari Games</a></li>
</ul>
</li>
<li>Using these models for simulation-based planning in agents remains a challenge for future work</li>
</ul>
</li>
<li>
<p>Human imagination</p>
<ul>
<li>Construct fictitious mental scenarios by recombining familiar elements in novel ways</li>
<li>Involves efficient representations that support generalization and transfer</li>
<li>"Jumpy": bridging multiple temporal scales at a time</li>
</ul>
</li>
</ul>
<h3 id="sota-2025_7">SOTA 2025</h3>
<ul>
<li>
<p>Model-Based RL &amp; World Models</p>
<ul>
<li><a href="https://arxiv.org/abs/2502.01591">2025. DeepMind. Improving Transformer World Models for Data-Efficient RL</a></li>
<li><a href="https://arxiv.org/abs/2301.04104">2023. DeepMind. Mastering Diverse Domains through World Models</a></li>
<li><a href="https://deepmind.google/discover/blog/genie-2-a-large-scale-foundation-world-model">2024. DeepMind. Genie 2: A large-scale foundation world model</a></li>
</ul>
</li>
<li>
<p><a href="https://arxiv.org/abs/2305.16291">2023. Wang. Voyager: An Open-Ended Embodied Agent with Large Language Models</a></p>
</li>
<li>
<p><a href="https://deepmind.google/discover/blog/alphageometry-an-olympiad-level-ai-system-for-geometry/">2024. DeepMind. AlphaGeometry: An Olympiad-level AI system for geometry</a></p>
</li>
</ul>
<h2 id="virtual-brain-analytics">Virtual Brain Analytics</h2>
<ul>
<li>
<p>Equivalents of single-cell recording, neuroimaging, and lesion techniques</p>
</li>
<li>
<p>Neuroscience: visualizing brain states through dimensionality reduction</p>
<ul>
<li><a href="https://arxiv.org/abs/1602.02658">2016. Zahavy. Graying the black box: Understanding DQNs</a></li>
</ul>
</li>
<li>
<p>Neuroscience: Receptive field mapping</p>
<ul>
<li><a href="https://arxiv.org/abs/1312.6034">2013. Simonyan. Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps</a></li>
<li>Activity maximization: a network learns to generate synthetic images by maximizing the activity of certain classes of unit<ul>
<li><a href="https://arxiv.org/abs/1605.09304">2016. Nguyen. Synthesizing the preferred inputs for neurons in neural networks via deep generator networks</a></li>
</ul>
</li>
</ul>
</li>
<li>
<p>Neuroscience-inspired analyses of linearized
networks</p>
<ul>
<li><a href="https://www.nature.com/articles/nrn1076">2003. McClelland. The parallel distributed processing approach to semantic cognition</a></li>
<li><a href="https://arxiv.org/abs/1312.6120">2013. Saxe. Exact solutions to the nonlinear dynamics of learning in deep linear neural networks</a></li>
</ul>
</li>
<li>
<p>Networks with external memory</p>
<ul>
<li><a href="https://web.stanford.edu/class/psych209/Readings/GravesWayne16DNC.pdf">2016. Graves. Hybrid computing using a neural network with dynamic external memory</a></li>
</ul>
</li>
<li>
<p>Hypothesis-driven experiments</p>
<ul>
<li><a href="https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268">2017. Jonas and Kording. Could a Neuroscientist Understand a Microprocessor?</a></li>
<li><a href="https://www.sciencedirect.com/science/article/pii/S0896627316310406">2017. Krakauer. Neuroscience Needs Behavior: Correcting a Reductionist Bias</a></li>
</ul>
</li>
<li>
<p>Circuits</p>
<ul>
<li><a href="https://distill.pub/2020/circuits/zoom-in">2020. Olah. Zoom In: An Introduction to Circuits</a></li>
</ul>
</li>
</ul>
<h3 id="sota-2025_8">SOTA 2025</h3>
<ul>
<li>
<p><a href="https://github.com/lutzroeder/netron">Netron: model visualizer</a></p>
</li>
<li>
<p><a href="https://github.com/pytorch/captum">pytorch/captum: Model interpretability and understanding</a></p>
</li>
<li>
<p><a href="https://github.com/jessevig/bertviz">BertViz: Visualize Attention</a></p>
</li>
</ul>
<h2 id="extra">Extra</h2>
<ul>
<li><a href="https://github.com/google/neural-tangents">google/neural-tangents: Infinite Width Neural Networks</a></li>
</ul>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "..", "features": [], "search": "../assets/javascripts/workers/search.d50fe291.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../assets/javascripts/bundle.56ea9cef.min.js"></script>
      
        <script src="../js/main.js"></script>
      
        <script src="../js/katex.js"></script>
      
        <script src="https://unpkg.com/katex@0/dist/katex.min.js"></script>
      
        <script src="https://unpkg.com/katex@0/dist/contrib/auto-render.min.js"></script>
      
    
  </body>
</html>